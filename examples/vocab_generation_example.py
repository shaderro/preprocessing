#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Vocabç”Ÿæˆç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨token_to_vocabæ¨¡å—ä»å¤„ç†åçš„æ–‡æœ¬ä¸­ç”Ÿæˆvocab
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.core.text_processor import TextProcessor
from src.utils.token_to_vocab import TokenToVocabConverter

def generate_vocab_from_text():
    """ä»æ–‡æœ¬ç”Ÿæˆvocabç¤ºä¾‹"""
    
    print("ğŸ” Vocabç”Ÿæˆç¤ºä¾‹")
    print("=" * 50)
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    Artificial intelligence has revolutionized the way we interact with technology. 
    Machine learning algorithms can process vast amounts of data to identify patterns 
    and make predictions. Deep learning networks, inspired by neural structures, 
    have achieved remarkable breakthroughs in image recognition and natural language processing.
    """
    
    print(f"ğŸ“ è¾“å…¥æ–‡æœ¬:\n{test_text.strip()}")
    print("-" * 30)
    
    try:
        # 1. ä½¿ç”¨TextProcessorå¤„ç†æ–‡æœ¬
        print("1. å¤„ç†æ–‡æœ¬...")
        processor = TextProcessor()
        original_text = processor.process_text_to_structured_data(test_text, 1, "AIæŠ€æœ¯æ–‡æœ¬")
        
        print(f"   âœ… å¤„ç†å®Œæˆï¼")
        print(f"   ğŸ“„ å¥å­æ•°é‡: {len(original_text.text_by_sentence)}")
        
        # ç»Ÿè®¡hardéš¾åº¦çš„token
        hard_tokens = []
        for sentence in original_text.text_by_sentence:
            for token in sentence.tokens:
                if token.token_type == "text" and token.difficulty_level == "hard":
                    hard_tokens.append(token.token_body)
        
        print(f"   ğŸ”¤ Hardéš¾åº¦token: {hard_tokens}")
        print()
        
        # 2. ä½¿ç”¨TokenToVocabConverterç”Ÿæˆvocab
        print("2. ç”Ÿæˆvocab...")
        converter = TokenToVocabConverter("vocab_data.json")
        vocab_expressions = converter.convert_tokens_from_text(original_text)
        
        print(f"   âœ… ç”Ÿæˆå®Œæˆï¼")
        print(f"   ğŸ“š ç”Ÿæˆvocabæ•°é‡: {len(vocab_expressions)}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„vocab
        for vocab in vocab_expressions:
            print(f"   - {vocab.vocab_body}: {vocab.explanation[:100]}...")
        
        print()
        
        # 3. ä¿å­˜vocabæ•°æ®
        print("3. ä¿å­˜vocabæ•°æ®...")
        converter.save_vocab_data(vocab_expressions)
        
        print()
        print("ğŸ‰ Vocabç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: vocab_data.json")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    generate_vocab_from_text()

if __name__ == "__main__":
    main() 